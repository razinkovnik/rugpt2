
Британская компания Google DeepMind представила новый алгоритм для синтеза человеческой речи под названием WaveNet. В его основе лежит использование нейросетей, что позволяет добиться более реалистичной имитации голоса. Статья разработчиков, описывающая программу, доступна на сайте компании.
Как правило, в системах преобразования текста в речь используются готовые аудиозаписи голоса людей. Программа выделяет из них звуки и компонует их на основе введенных данных, что позволяет добиться довольно естественного звучания — хорошим примером в данном случае может служить помощник Siri или Google Assistant. Однако такой подход, известный как компиляционный синтез, весьма ограничен, так как для того, чтобы можно было создать нового голосового ассистента или просто изменить тон речи, требуется наличие человека, который запишет все возможные звуки для базы данных.Образец компиляционного синтеза речи:Существует также и альтернативный метод, параметрический синтез, которой использует полностью сгенерированный компьютером голос, и не требует библиотеки «живой» речи. Его работа основывается на уже заданных параметрах, соответствующих правилам грамматики и принципам произнесения звуков. Тем не менее, на выходе получается достаточно «машинная» по звучанию речь.
Образец параметрического синтеза речи:Работа алгоритма WaveNet заключается в поточечной генерации профиля звуковой волны с помощью специальной нейросети. Ее обучили с помощью записей голоса диктора, но звуковые фрагменты этой базы система не использует, она генерирует их самостоятельно. При создании программы разработчики использовали нейросеть типа FCN (Fully convolutional network), архитектура которой была вдохновлена рекуррентной нейросетью PixelRNN и сверточной нейросетью PixelCNN. Каждый сверточный слой в этой сети имеет свой множитель расширения, благодаря которому ее рецептивное поле, то есть часть информации, которую обрабатывают нейроны, растет экспоненциально. В сущности, это позволяет программе охватывать сразу большое количество временных шагов. В нейросети также предусмотрена обратная связь, поэтому каждый последующий звук машинной речи генерируется на основе множества предыдущих. Как сообщают разработчики, WaveNet может помнить 2–3 предыдущие фонемы.
