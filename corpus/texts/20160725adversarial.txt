
Сотрудники Google Brain и исследовательской
компании OpenAI создали метод обмана
распознающих изображения нейросетей,
который работает даже в офлайне —
получаемые им изображения обманывают
компьютер не только когда их напрямую
«скармливают» нейросети, но и тогда,
когда их распечатывают, фотографируют
и только потом пытаются распознать.
Описание нового метода и исследование
его применимости опубликовано в архиве
препринтов arXive.org
Речь идет о изображениях-обманках
(adversarial examples), которые можно сделать на
основе любой исходной картинки. Для
человека такие изображения почти не
отличимы от оригинала, однако в них
внесены некоторые изменения, которые
существенно усложняют их распознавание
нейросетью. Потенциально, такие
изображения можно использовать для
обхода автоматических фильтров спама,
систем распознавания лиц или для подделки
биометрии. 
Методы создания обманок для нейросетей
разного типа (распознающих не только
изображения, но и, например, звуки)
исследуются как минимум с 2004 года.
Традиционно для этого используются
соперничающие нейросети, одна из которых
стемится создать обманку, а другая —
правильно ее идентифицировать (отсюда
терминология adversarial examples, т. е.
соперничающих примеров). Однако важные
практические результаты в этой области
получены только в последние несколько
лет. Например, в одном из исследований
ученым удалось модифицировать музыкальные
аудизаписи таким образом, что нейросеть
смартфона могла их идентифицировать и
исполнять как голосовые команды, в то
время как человек вообще не замечал
постороннего вмешательства в музыку.
В области распознавания изображений
подобные эксперименты также уже
проводились, однако до сих пор они
преимущественно оставались in silico, то
есть изображения-обманки напрямую
передавали нейросети для распознавания.
Однако технология создания обманок
подразумевает введение очень тонких,
незаметных изменений, которые могут
теряться при масштабировании, затенении,
обесцвечивании и других искажениях,
которые неизбежно появляются при
фотографировании через камеру. Поэтому
неизвестно, насколько создание обманок
может быть опасно для нейросетей в
реальной жизни. В новой работе ученые
исследовали устойчивоть существующих
методов создания обманок к подобным
искажениям и разработали новый алгоритм,
который делает обманки гораздо эффективнее
известных аналогов. 
За основу в работе были взяты изображения
из стандартной базы ImageNet, которые ученые
 модифицировали одним из трех алгоритмов
и затем отдавали на распознавание
неросети Google’s Inception v3. Часть изображений
нейросеть получала напрямую, часть
авторы статьи распечатывали на бумаге
и фотографировали на камеру современного
смартфона. В работе ученые проверяли,
как влияет на уровень ошибок нейросети
не только тип алгоритма, но и степень контрастности,
яркости и «замыленности» снимков.
