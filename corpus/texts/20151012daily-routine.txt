
Исследователи из Технологического института Джорджии при помощи глубокого обучения нейросетей смогли научить алгоритм определять по снимкам от первого лица характер активности, в которую вовлечен человек. С полным текстом исследования можно ознакомиться на сайте института.В рамках исследования участник эксперимента на протяжении шести месяцев носил на груди смартфон в чехле. Установленное на мобильном устройстве приложение делало снимки от первого лица с частотой раз в минуту в первые недели исследования, позже интервал увеличили до одной фотографии раз в пять минут. При этом в обязанности испытуемого входило присвоение фотографиям меток о текущей активности. Одной из важных проблем при сборе данных авторы считали возможное нарушение неприкосновенности частной жизни как испытуемого и его семьи, так и людей, которые случайно попали в объектив камеры. Для того, чтобы учесть этот нюанс, испытуемый каждый вечер фильтровал снимки и удалял нежелательные, по его мнению, фотографии.После того, как сбор данных был окончен, исследователи отобрали 40 тысяч фотографий, сделанных за этот период и правильно помещенных в одну из 19 категорий: работа по дому, вождение, готовка, физическая тренировка, чтение, выступление, собаки, отдых, еда, работа, разговор, просмотр телевизора, встреча, уборка, совместное времяпровождение, ходьба по магазинам, езда на велосипеде, семья и гигиена. Также для каждой фотографии было указано время, в которое сделан снимок.
