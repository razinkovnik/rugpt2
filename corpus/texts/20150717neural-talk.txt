
Ученые из Стэнфордского университета создали программу, которая способна описывать содержание фотографий связными предложениями. В качестве исходных данных требуется только изображение, а на выходе алгоритм выдает текст, например «Мужчина в черной футболке играет на гитаре». Описание работы приводится в препринте на arXiv.org (последняя редакция манускрипта была добавлена 14 апреля, однако СМИ обратили на него внимание только сейчас).Ученые разбили задачу на две стадии. Сперва подпрограмму учили находить на фотографиях участки, соответствующие словам из уже созданного текстового описания. После этого другую подпрограмму обучали подбирать описательные слова к разным регионам фотографии и затем объединять их в предложения.Для реализации обоих стадий алгоритма ученые использовали искусственные нейронные сети. Их обучали на подборках фотографий Flickr8K, Flickr30K и MSCOCO, в которых почти 150000 снимков были подписаны при помощи краудсорсинговой платформы Amazon Mechanical Turk.После обучения нейронных сетей авторы тестировали работу алгоритма на фотографиях, которых не было в тренировочной базе. Результаты эксперимента ученые сравнивали с аналогичными программами. В качестве критериев использовалась степень соответствия с подписями, которые были созданы людьми.
