
Ученые из Массачусетского технологического института и Стэнфордской лаборатории искусственного интеллекта создали систему искусственного интеллекта, которая способна озвучить «немое» видео, генерируя звуки на основе предсказанных свойств объектов. Исследование авторов будет представлено на ежегодной конференции по машинному зрению и распознаванию образов (CVPR), также оно выложено на сайте ArXiv.
Для своей работы ученые использовали систему искусственного интеллекта на основе сверточной и рекуррентной нейросети. Они создали 977 видеороликов, в которых люди с помощью барабанной палочки бьют и царапают объекты из разных материалов, — в сумме было совершено 46577 действий. Исследователи вручную разметили видеоряд, указав тип материала, место удара, характер действия (удар или царапина), а также ответную реакцию на удар (разбрасывание, деформация или всплеск). Эти метки использовались только для того, чтобы оценить работу системы, а не для ее обучения.
