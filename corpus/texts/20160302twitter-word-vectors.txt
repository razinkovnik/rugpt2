
Николай Васильев, разработчик из итальянской компании SpazioDati, проследил, насколько русский сегмент Twitter подходит в качестве основы для базы семантических векторов: количественных представлений слов, описывающих их контекстное значение. Оказалось, что даже сравнительно короткие выборки твитов не намного уступают более крупным корпусам данных (архивам книг или Википедии), однако при этом Twitter позволяет уловить наиболее актуальные контексты, зачастую недоступные более статичным базам текстов. Препринт исследования выложен на arXiv.org.Автор использовал в общей сложности 50 миллионов русскоязычных твитов за период с 21.07.2015 по 04.08.2015. Из них отбирались слова, встречающиеся не менее 40 раз, и для каждого составлялся собственный контекстный вектор. Он показывал, как часто данное слово встречалось рядом (в рамках n соседних слов) с 300 заранее выбранными словами, таким образом описывая его характерный контекст.Васильев сравнивал полученное контекстное представление с рядом других аналогичных результатов, полученных ранее в рамках конференции RUSSE: The First Workshop on Russian Semantic Similarity. Эти представления были получены на крупных базах текстов, таких как сайт lib.rus.ec (12 миллиардов слов) или русскоязычный сегмент Википедии. В качестве эталона использовалось контекстное представление из 333 пар слов, составленное добровольцами при помощи краудсорсинга.Для представлений, созданных при использовании Twitter, коэффициент корреляции векторов с эталоном достиг 60 процентов, что лишь на 5 процентов меньше, чем у представления, построенного на базе lib.rus.ec. Автор замечает (но не вдается в подробности), что несмотря на неплохую корреляцию, векторы на основе твитов не очень хорошо подходили для решения семантических задач, однако, позволяли зафиксировать наиболее актуальные контексты слов. В будущем Васильев планирует подробнее исследовать контекстное значение хештегов и ников, часто встречающихся в тексте твитов.Контекстные векторы получили широкое распространение сравнительно недавно, хотя были предложены еще в середине XX века. Их нынешнюю популярность связывают с развитием методов машинного обучения, позволяющих эффективно работать с крупными базами текстов. Правильно подобранный «словарь» для контекстных векторов позволяет (по крайней мере, в идеальном случае) производить со словами математические операции. Например, прибавив к вектору слова «табуретка» вектор слова «спинка» можно получить вектор слова «стул».Тарас Молотилин
