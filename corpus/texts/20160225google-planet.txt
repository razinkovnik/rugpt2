
Коллектив ученых из Google и Рейнско-Вестфальского технического университета Ахена создал программу PlaNet, которая по фотоснимку (любому, даже изображению еды или домашнего животного) определяет, в какой точке Земли он был сделан. Новый алгоритм основан на обучении искусственной нейронной сети и отличается от предшественников тем, что опирается не только на какие-либо хорошо известные достопримечательности, а использует весь доступный комплекс деталей, например, пейзаж, цвета, особенности архитектуры, присутствие характерных животных и растений. Препринт работы выложен на arXiv.org.Авторы собрали базу из 126 миллионов фотографий с доступными тегами геолокации, а затем разбили поверхность земли на квадраты так, чтобы на каждый из них приходилось не более 10000 снимков. Таким образом, сетка разбиения была реже в малонаселенных регионах и гуще, например, в крупных городах. Квадраты, на которые приходилось меньше 50 фотографий (океаны, крайний север), в работу вообще не включали.Используя три четверти отобранных фотографий, исследователи обучали сверточную нейронную сеть, которая на выходе выдавала распределение вероятностей по квадратам: чем больше значение, тем больше вероятность, что снимок был сделан в этом регионе. Параметры подбирались так, чтобы для фото с известным геотегом вероятность в «нужном» квадрате стремилась к 100 процентам, а во всех остальных — к нулю.
