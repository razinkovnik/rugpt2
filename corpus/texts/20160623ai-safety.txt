
Компании Google и OpenAI совместно с Калифорнийским
университетом в Беркли и Стэнфордским университетом сформулировали пять практических
проблем, которые необходимо учитывать разработчикам искусственного интеллекта. Препринт
их статьи доступен на ресурсе arXiv.org.
Как пишет сотрудник Google и один из авторов публикации Крис Ола (Chris Olah) в корпоративном блоге, хотя связанные с
ИИ риски привлекают большое общественное внимание, дискуссии по их поводу
обычно слишком гипотетические и спекулятивные. Статья призвана конкретизировать
потенциальные опасности, которые необходимо учитывать при разработках в этом
направлении.
Среди проблем, которые должны учитывать разработчики систем
ИИ для практического применения, авторы работы выделяют следующие:
избегание нежелательных побочных эффектов (например, робот
может разбить вазу, если это ускорит процесс уборки);избегание жульничества (тот же робот может просто прикрыть
мусор, а не убрать его);гибкая потребность в надзоре (например, если робот может
посоветоваться с человеком при выполнении задачи, он не должен надоедать
вопросами);безопасное обучение (упомянутому роботу-уборщику не стоит
экспериментировать с протиркой розеток мокрой тряпкой);устойчивость к смене деятельности (например, уборка в цехе
металлообработки и химической лаборатории принципиально отличается).
Среди возможных путей решения исследователи называют
использование симуляций в обучении, ограничение пространства деятельности
роботов и человеческий надзор, однако ни один из них не представляет
окончательного решения проблемы. По мнению специалистов Google, обеспечить заданную работу
систем машинного обучения могут только ответственные, открытые и междисциплинарные
усилия разработчиков.
Олег Лищук
