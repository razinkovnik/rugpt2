
«Яндекс» запустил новый поисковый алгоритм «Палех», в основе которого лежит использование нейронных сетей. Благодаря «Палеху» поиск лучше находит страницы, которые соответствуют не только ключевым словам, но и смыслу запроса. Об этом компания сообщает в своем блоге.
Обработка поисковых запросов — это сложная и порой нетривиальная задача для решения которой, как правило, успешно используется машинное обучение. Однако оно имеет некоторые ограничения: дело в том, что для обучения искусственного интеллекта необходимо большое количество разнообразной пользовательской статистики. Эта статистика существует в большом объеме для популярных и среднечастотных запросов, но практически отсутствует для уникальных запросов — то есть тех, которые не повторяются хотя бы дважды в течение всего периода наблюдений. При этом, до 40 процентов поисковых запросов в Яндексе являются именно уникальными (их еще называют «длинным хвостом», так как они составляют существенную долю обращений к поиску): это могут быть запросы от детей, которые обращаются к системе, как к живому собеседнику («дорогой яндекс посоветуй пожалуйста новые интересные игры про фей для плантика»), или запросы от людей, которые хотят узнать название фильма или книги по эпизоду («фильм про человека который выращивал картошку на другой планете»). Трудность их обработки заключается в том, что поисковику в таком случае необходимо искать не только соответствие по словам, но и по смыслу.
Разработчики «Яндекса» запустили новый алгоритм, который позволяет справиться с этой проблемой. Он был назван «Палех» в честь Жар-птицы с длинным хвостом, которая часто появляется на палехской миниатюре. В основе «Палеха» лежит использование нейросети и метод семантических векторов. 
Разработка и обучение нейросети происходили в несколько этапов. Сначала исследователи использовали модель разработчиков из Microsoft Research под названием Deep Structured Semantic Model. На ее вход подавались тексты запросов и заголовков, которые разбивались на буквенные триграммы (для запроса «палех» получаются триграммы «па», «але», «лех», «ех»). Так как словарь всех известных триграмм ограничен, то
текст запроса можно представить в виде вектора размером в несколько десятков тысяч элементов, и отметить вхождение триграмм из запроса в словарь (совпадающие триграммы отмечаются единицей, остальные — нулем). Сравнивая эти векторы можно узнать о наличии совпадающих триграмм в заголовке страницы и запросе, однако для получения вектора со «свойствами семантической близости» исследователи выполняли преобразование. Его суть заключалась в том, что на выходе модель выдавала результат скалярного умножения последних векторов заголовка и запроса. Система обучалась таким образом, что для положительных обучающих примеров выходное значение было большим, а для отрицательных — маленьким. Сравнивая векторы последнего слоя, исследователи могли вычислить ошибку предсказания и «подкрутить» нейросеть так, чтобы эта ошибка уменьшилась.
